# Results


```{r echo=FALSE}

set.seed(1)

credit <- read.csv("http://www-bcf.usc.edu/~gareth/ISL/Credit.csv")
credit <- credit[,c(2:12)]

temp_credit <- model.matrix(Balance ~ ., data = credit)
new_credit <- cbind(temp_credit[ ,-1], Balance = credit$Balance)

scaled_credit <- scale(new_credit, center = TRUE, scale = TRUE)
write.csv(scaled_credit, file = "data/scaled-credit.csv")

set.seed(1)

train_indices <- sample(1:400,300)
test_indices <- which(!(c(1:400) %in% train_indices))

credit_train <- scaled_credit[train_indices,]
credit_test  <- scaled_credit[-train_indices,]

suppressMessages(library(glmnet))

grid = 10^seq(10, -2, length = 100)

set.seed(1)

x <- model.matrix(Balance ~ ., data = data.frame(credit_train))
y <- data.frame(credit_train)$Balance

lasso_mod <- cv.glmnet(x, y, intercept=FALSE, standardize=FALSE, lambda = grid, alpha=1)

lasso_best_mod <- lasso_mod$lambda.min

lasso_pred <- predict(lasso_mod, s = lasso_best_mod, newx= model.matrix(Balance ~ ., data = data.frame(credit_test)))

lasso_mse <- mean((lasso_pred - credit_test[,12])^2)

lasso_fit_full <- cv.glmnet(model.matrix(Balance ~ .,data = data.frame(scaled_credit)),
                            data.frame(scaled_credit)$Balance,
                            intercept = FALSE,
                            standardize = FALSE, 
                            alpha=1)

lasso_pred_full <- predict (lasso_fit_full, type="coefficients", s = lasso_best_mod)

ols<-lm(Balance~Income+Limit+Rating+Cards+Age+Education
        +GenderFemale+StudentYes+MarriedYes+EthnicityAsian
        +EthnicityCaucasian, 
        data=as.data.frame(scaled_credit))

summary_ols <- summary(ols)`
mse_ols <- mean(ols$residuals^2)

suppressMessages(library(pls))
set.seed(1)

pcr_fit=pcr(Balance ~ ., 
             data = data.frame(credit_train),
             scale = FALSE,
             validation = "CV")

best_mod_comp_pcr <- which.min(pcr_fit$validation$PRESS)

pcr_pred = predict(pcr_fit, 
                   credit_test[,-12],
                   ncomp = best_mod_comp_pcr)

pcr_mse <- mean((pcr_pred - credit_test[,12])^2)

pcr_fit_full <- pcr(Balance ~ .,
                     data = data.frame(scaled_credit),
                     scale = FALSE, 
                     ncomp = best_mod_comp_pcr)
                     
pcr_full_coefs <- coefficients(pcr_fit_full)

set.seed(1)

pls_fit=plsr(Balance ~ ., 
             data = data.frame(credit_train),
             scale = FALSE,
             validation = "CV")
             
best_mod_comp_pls <- which.min(pls_fit$validation$PRESS)

pls_pred = predict(pls_fit, 
                   credit_test[,-12],
                   ncomp = best_mod_comp_pls)


pls_mse <- mean((pls_pred - credit_test[,12])^2)

pls_fit_full <- plsr(Balance ~ .,
                     data = data.frame(scaled_credit),
                     scale = FALSE, 
                     ncomp = 5)

pls_full_coefs <- coefficients(pls_fit_full)

set.seed(1)

grid <- 10^seq(10, -2, length = 100)

set.seed(1)
x <- model.matrix(Balance ~ ., data = data.frame(credit_train))
y <- data.frame(credit_train)$Balance

ridge_mod <- cv.glmnet(x, y, intercept = FALSE, standardize = FALSE, lambda = grid, alpha = 0)


ridge_best_labmda <- ridge_mod$lambda.min

ridge_pred <- predict(ridge_mod,
                      s= ridge_best_labmda,
                      newx= model.matrix(Balance ~ ., data = data.frame(credit_test)))

ridge_mse <- mean((ridge_pred - credit_test[,12])^2)

ridge_fit_full <- cv.glmnet(model.matrix(Balance ~ .,data = data.frame(scaled_credit)),
                            data.frame(scaled_credit)$Balance, 
                            intercept = FALSE,
                            standardize = FALSE,
                            alpha = 0)


ridge_pred_full <- predict (ridge_fit_full, type="coefficients", s= ridge_best_labmda)
```




Here is a table of the coefficients we get after fitting the models:

```{r, echo=FALSE}
suppressMessages(library(xtable))


v <-as.vector(ols$coefficients)[-c(1)]
w <-as.vector(ridge_pred_full)[-c(1,2)]
x <-as.vector(lasso_pred_full)[-c(1,2)]
y <-as.vector(pcr_full_coefs)
z <-as.vector(pls_full_coefs)
coef_names<-c("Income", "Limit", "Rating", 
              "Cards", "Age", "Education", 
              "GenderFemale", "StudentYes", 
              "MarriedYes","EthnicityAsian",
              "EthnicityCaucasian")
names(v)<- coef_names
names(w)<- coef_names
names(x)<- coef_names
names(y)<- coef_names
names(z)<- coef_names
v_name <- "OLS"
w_name <- "Ridge"
x_name <- "LASSO"
y_name <- "PCR"
z_name <- "PLS"
df <- data.frame(v,w,x,y,z)
names(df)<-c(v_name,w_name,x_name,y_name,z_name)
coef_tbbl<-xtable(df, type="latex")
print(coef_tbbl)
```

This is a graphical representation of the coefficients:

```{r, echo=FALSE}
suppressMessages(library(ggplot2))


v <-as.vector(ols$coefficients)[-c(1)]
w  <-append(v, as.vector(ridge_pred_full)[-c(1,2)],
           after = length(v))
x <-append(w, as.vector(lasso_pred_full)[-c(1,2)],
           after = length(w))
y <-append(x, as.vector(pcr_full_coefs),
           after = length(x))
z <-append(y, as.vector(pls_full_coefs),
           after = length(x))

a<-c("Income", "Limit", "Rating", 
              "Cards", "Age", "Education", 
              "GenderFemale", "StudentYes", 
              "MarriedYes","EthnicityAsian",
              "EthnicityCaucasian")
b<- c(rep(a, times=5))


h<- c(rep("OLS",times=11), rep("Ridge",times=11),
      rep("LASSO",times=11),rep("PCR",times=11),
      rep("PLS",times=11))


z_name <- "CoefficientValue"
b_name <- "Variable"
h_name <- "Model"
coeff_df <- data.frame(z,b,h)
names(coeff_df)<-c(z_name, b_name, h_name)

ggplot(data=coeff_df,aes(x=Variable,y=CoefficientValue))+
  geom_bar(stat = "identity")+
  facet_wrap(~Model)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Here are the MSE's of each regression:

```{r, echo=FALSE}
suppressMessages(library(xtable))

names(ridge_mse)<-"MSE"
names(lasso_mse)<-"MSE"
names(pcr_mse)<-"MSE"
names(pls_mse)<-"MSE"
mse_df<-data.frame(ridge_mse,lasso_mse,pcr_mse,pls_mse)
names(mse_df)<-c("Ridge", "LASSO","PCR","PLS")
mse_tbbl<-xtable(mse_df,type="latex")
print(mse_tbbl)
```

  
  For our analysis, 
  
  Ridge Regression, with 11 components, resulted in an MSE of `r ridge_mse` 
  
  LASSO performed best with 7 components. The full model fit with this number of components resulted in an MSE of `r lasso_mse`
  
  Principal Components Regression performed best with 11 components. The full model fit with this number of components resulted in an MSE of `r pcr_mse`
  
  Partial Least Squares Regression performe best with 11 components. The model fit with this number of components resulted in an MSE of `r pls_mse`

```{r,echo=FALSE}
min_mse_vec<-c(ridge_mse,lasso_mse,pcr_mse,pls_mse)
names(min_mse_vec)<-c("Ridge","LASSO","PCR","PLS")
```

Thus, our best performing model, with an MSE of `r min(min_mse_vec)`, is `r names(min(min_mse_vec))`. 

